defaults:

  imagePullSecrets:
    allowNone: [< .ImagePullSecrets.AllowNone >]
    useExisting: []
    useFromDefaultServiceAccount: true

  image:
    registry: [< required "" .MainRegistry >]

  env:
    offlineMode: false

  central:
    config: "@config/central/config.yaml|config/central/config.yaml.default"
    endpointsConfig: "@config/central/endpoints.yaml|config/central/endpoints.yaml.default"

    exposeMonitoring: false

    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        # Central is single-homed, so avoid preemptible nodes.
        - weight: 100
          preference:
            matchExpressions:
            - key: cloud.google.com/gke-preemptible
              operator: NotIn
              values:
                - "true"
        - weight: 50
          preference:
            matchExpressions:
            - key: node-role.kubernetes.io/infra
              operator: Exists
        - weight: 25
          preference:
            matchExpressions:
            - key: node-role.kubernetes.io/compute
              operator: Exists
        # From v1.20 node-role.kubernetes.io/control-plane replaces node-role.kubernetes.io/master (removed in
        # v1.25). We apply both because our goal is not to run pods on control plane nodes for any version of k8s.
        - weight: 100
          preference:
            matchExpressions:
            - key: node-role.kubernetes.io/master
              operator: DoesNotExist
        - weight: 100
          preference:
            matchExpressions:
            - key: node-role.kubernetes.io/control-plane
              operator: DoesNotExist

    image:
      name: [< required "" .ImageRemote >]
      tag: [< required "" .ImageTag >]

    resources:
      requests:
        memory: "4Gi"
        cpu: "1500m"
      limits:
        memory: "8Gi"
        cpu: "4000m"

    exposure:
      loadBalancer:
        enabled: false
        port: 443
      nodePort:
        enabled: false
        port: null
      route:
        enabled: false
    db:
      external: false

      source:
        minConns: 10
        maxConns: 90
        statementTimeoutMs: 1200000

      postgresConfig: "@config/centraldb/postgresql.conf|config/centraldb/postgresql.conf.default"
      hbaConfig: "@config/centraldb/pg_hba.conf|config/centraldb/pg_hba.conf.default"

      image:
        name: [< required "" .CentralDBImageRemote >]
        tag: [< required "" .CentralDBImageTag >]

      resources:
        requests:
          memory: "8Gi"
          cpu: "4"
        limits:
          memory: "16Gi"
          cpu: "8"
  scanner:
    disable: false
    replicas: 3
    logLevel: INFO
    mode: full

    autoscaling:
      disable: false
      minReplicas: 2
      maxReplicas: 5

    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app: scanner
            topologyKey: kubernetes.io/hostname
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 50
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/infra
                operator: Exists
        - weight: 25
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/compute
                operator: Exists
        # From v1.20 node-role.kubernetes.io/control-plane replaces node-role.kubernetes.io/master (removed in
        # v1.25). We apply both because our goal is not to run pods on control plane nodes for any version of k8s.
        - weight: 100
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
        - weight: 100
          preference:
            matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: DoesNotExist

    resources:
      requests:
        memory: "1500Mi"
        cpu: "1000m"
      limits:
        memory: "4Gi"
        cpu: "2000m"

    image:
      name: [< required "" .ScannerImageRemote >]
      tag: [< required "" .ScannerImageTag >]

    dbResources:
      limits:
        cpu: "2000m"
        memory: "4Gi"
      requests:
        cpu: "200m"
        memory: "512Mi"

    dbImage:
      name: [< required "" .ScannerDBImageRemote >]
      tag: [< required "" .ScannerImageTag >]

[<- if .FeatureFlags.ROX_SCANNER_V4_SUPPORT >]
  scannerV4:
    disable: true
    image:
      name: [< required "" .ScannerV4ImageRemote >]
      tag: [< required "" .ScannerV4ImageTag >]
    indexer:
      disable: false
      logLevel: INFO
      metricsPort: 9090
      replicas: 3
      autoscaling:
        minReplicas: 2
        maxReplicas: 5
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: scanner-v4-indexer
              topologyKey: kubernetes.io/hostname
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/infra
                operator: Exists
          - weight: 25
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/compute
                operator: Exists
          # From v1.20 node-role.kubernetes.io/control-plane replaces node-role.kubernetes.io/master (removed in
          # v1.25). We apply both because our goal is not to run pods on control plane nodes for any version of k8s.
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: DoesNotExist
      resources:
        requests:
          memory: "1500Mi"
          cpu: "1000m"
        limits:
          memory: "3Gi"
          cpu: "2000m"
    matcher:
      logLevel: INFO
      metricsPort: 9090
      replicas: 2
      autoscaling:
        minReplicas: 2
        maxReplicas: 3
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: scanner-v4-matcher
              topologyKey: kubernetes.io/hostname
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/infra
                operator: Exists
          - weight: 25
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/compute
                operator: Exists
          # From v1.20 node-role.kubernetes.io/control-plane replaces node-role.kubernetes.io/master (removed in
          # v1.25). We apply both because our goal is not to run pods on control plane nodes for any version of k8s.
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: DoesNotExist
      resources:
        requests:
          memory: "4Gi"
          cpu: "1000m"
        limits:
          memory: "5Gi"
          cpu: "2000m"
    db:
      postgresConfig: "@config-templates/scanner-v4-db/postgresql.conf|config-templates/scanner-v4-db/postgresql.conf.default"
      hbaConfig: "@config-templates/scanner-v4-db/pg_hba.conf|config-templates/scanner-v4-db/pg_hba.conf.default"
      source:
        minConns: 5
        maxConns: 40
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          # Scanner V4 DB is single-homed, so avoid preemptible nodes.
          - weight: 100
            preference:
              matchExpressions:
              - key: cloud.google.com/gke-preemptible
                operator: NotIn
                values:
                  - "true"
          - weight: 50
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/infra
                operator: Exists
          - weight: 25
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/compute
                operator: Exists
          # From v1.20 node-role.kubernetes.io/control-plane replaces node-role.kubernetes.io/master (removed in
          # v1.25). We apply both because our goal is not to run pods on control plane nodes for any version of k8s.
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: DoesNotExist
          - weight: 100
            preference:
              matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: DoesNotExist
      resources:
        requests:
          cpu: "200m"
          memory: "3Gi"
        limits:
          cpu: "2000m"
          memory: "4Gi"
      image:
        name: [< required "" .ScannerV4DBImageRemote >]
        tag: [< required "" .ScannerV4ImageTag >]
    exposeMonitoring: false
[<- end >]

  system:
    [<- if not .AutoSensePodSecurityPolicies >]
    enablePodSecurityPolicies: [< .EnablePodSecurityPolicies >]
    [<- end >]

pvcDefaults:
  claimName: "stackrox-db"
  size: "100Gi"

dbPVCDefaults:
  claimName: "central-db"
  size: "100Gi"

[<- if .FeatureFlags.ROX_SCANNER_V4_SUPPORT >]
scannerV4DBPVCDefaults:
  claimName: "scanner-v4-db"
  size: "50Gi"
  createClaim: true
[<- end >]
