---
title: "Machine learning based ranking for risk"
subtitle: "Intelligent risk recommendations for ACS"
author: "Stephan HeÃŸelmann"
date: "2025-11-05"
format:
  revealjs:
    chalkboard:
      buttons: false
    css: styles.css
    footer: "ACS Engineering | Frankfurt meetup 2025"
    preview-links: auto
    slide-number: true
    theme: simple
---

## Agenda

::: incremental
1. **The Challenge**: Why we need machine learning for risk ranking
2. **The Algorithm**: How random forests work (simple explanation)
3. **Training Pipeline**: From Central data to trained model
4. **Predictions**: How to rank deployments in production
5. **Vibe Coding**: Current prototype status
6. **Roadmap**: Possible improvements
:::

# The Challenge {background-color="#2d2d2d"}

## What Is Risk?

::: columns
::: {.column width="50%"}
::: incremental
- **ACS monitors thousands of deployments** across customer clusters
- Each deployment has **dozens of security characteristics**:
  - Policy violations
  - CVE vulnerabilities
  - Privileged containers
:::
:::

::: {.column width="50%"}
::: incremental
-
  - Network exposure
  - Process anomalies
  - ... and many more

- **Question:** Which deployments should security teams focus on first?
:::
:::
:::

## The Existing Risk Feature

![Current risk assessment in ACS](diagrams/current-risk.png){width="80%"}

## Shortcomings of Current Approach

::: incremental
- **ðŸ”’ Intransparent**
  - The risk score is baked into ACS with a hidden and complex formula.
  - Customers cannot understand or validate how scores are calculated.

- **âš™ï¸ Inflexible**
  - Does not adapt to individual customer needs or emerging trends.
  - One-size-fits-all approach across all environments.
:::

## Current Approach: Rule-Based Multipliers

```
Risk Score =
  Policy Violations Ã—
  Process Baseline Ã—
  Vulnerabilities Ã—
  Risky Components Ã—
  Component Count Ã—
  Image Age Ã—
  ...
```

## The ML Solution

::: incremental
- **Learn** from historical deployment data
- **Identify** which security features matter most
- **Rank** deployments by actual risk, not just rules
- **Explain** why a deployment is high-risk
- **Improve** continuously as new data arrives
:::

::: {.fragment}
**Key Innovation:** Model learns to reproduce StackRox risk logic, then improves beyond it
:::

# The Algorithm {background-color="#2d2d2d"}

## RandomForest: The Committee Approach

**Analogy:** Assessing fire risk for a house

::: incremental
- Instead of **1 inspector** with a rigid checklist...
- Ask **1000 inspectors** to each create their own evaluation method
- Each inspector looks at different combinations of factors:
  - Electrical wiring + smoke detectors
  - Flammable materials + escape routes
  - Building age + maintenance history
- **Final assessment** = average of all 1000 opinions
:::

## RandomForest Architecture

![](diagrams/randomforest-architecture.svg){fig-align="center" width="90%"}

::: {.notes}
- 1000 decision trees built independently
- Each tree sees random subset of features
- Predictions are averaged for final score
:::

## Why RandomForest?

::: incremental
1. **Robust**
   - If one tree makes a mistake, 999 others can correct it
   - Not sensitive to outliers or noisy data

2. **Handles Complexity**
   - Learns non-linear relationships automatically
   - No manual feature engineering required

3. **Provides Explanations**
   - Feature importance: which security issues matter most
   - Per-prediction explanations available

4. **Simple Training**
   - No epochs, no backpropagation, no GPUs required
   - Builds all 1000 trees in parallel (~30 seconds)
:::

## Example: One Decision Tree

```
Is vulnerability_score > 7.5?
â”œâ”€ YES â†’ Is privileged_container_ratio > 0.5?
â”‚         â”œâ”€ YES â†’ Risk Score = 8.2
â”‚         â””â”€ NO â†’ Is external_exposure = 1?
â”‚                  â”œâ”€ YES â†’ Risk Score = 6.5
â”‚                  â””â”€ NO â†’ Risk Score = 4.1
â””â”€ NO â†’ Is policy_violation_score > 3.0?
         â”œâ”€ YES â†’ Risk Score = 5.0
         â””â”€ NO â†’ Risk Score = 2.3
```

::: {.fragment}
**Final Prediction:** Average of 1000 such trees
:::

# Training Pipeline {background-color="#2d2d2d"}

## End-to-End Training Flow

![](diagrams/training-pipeline.svg){fig-align="center" width="100%"}

## Feature Categories

![](diagrams/feature-categories.svg){fig-align="center" width="95%"}

## Security Features (20+ extracted)

:::: {.columns}
::: {.column width="50%"}
**Deployment Configuration**

- Policy violation score
- Privileged container ratio
- Host network/PID/IPC access
- Service account tokens

**Network Exposure**

- External exposure flag
- Exposed port count (log scale)
:::

::: {.column width="50%"}
**Vulnerabilities**

- Average/max CVE severity
- Average/max CVSS scores
- Total vulnerability burden

**Image Security**

- Risky component count
- Total component count
- Image age (days)
- Process baseline violations
:::
::::

## Synthetic vs Real Risk Scores

::: incremental
**Bootstrap Phase (Synthetic Scoring):**

- Calculate risk using StackRox's multiplier system
- Model learns to reproduce existing logic
- Provides baseline for initial deployment

**Production Phase (Real Scoring):**

- Human analysts or automated systems provide ground truth
- Model learns from actual security outcomes
- Improves beyond initial rule-based system
:::

## Model Configuration

```yaml
model:
  algorithm: sklearn_ranksvm

  sklearn_params:
    n_estimators: 1000      # 1000 decision trees
    max_depth: 25           # Tree depth
    min_samples_split: 10   # Minimum samples to split
    min_samples_leaf: 4     # Minimum samples in leaf
    max_features: "sqrt"    # Features per split
    n_jobs: -1              # Use all CPU cores
```

::: {.fragment}
**Training Time:** ~30 seconds for 1000 deployments
:::

## Performance Metric: NDCG

**NDCG = Normalized Discounted Cumulative Gain**

::: incremental
- Measures **ranking quality** on 0-1 scale
- Values closer to **1.0** = better ranking
- Industry standard for search engines and recommender systems

**Example:**
```
True ranking:  [10, 9, 8, 7, 6, 5, 4, 3, 2, 1]
Model ranking: [10, 8, 9, 7, 6, 5, 4, 3, 2, 1]
                    â†‘ Small error at top
NDCG â‰ˆ 0.98  (98% as good as perfect ranking)
```
:::

## Typical Performance

:::: {.columns}
::: {.column width="50%"}
**Training Metrics**

- Training NDCG: **0.95-0.99**
- Validation NDCG: **0.85-0.95**
- Training time: **~30 sec**
:::

::: {.column width="50%"}
**Model Characteristics**

- Feature count: **~20**
- Training samples: **1000-10000**
- Model size: **~5-20 MB**
- Trees: **1000**
:::
::::

::: {.fragment}
**Validation NDCG > 0.85** means model ranks deployments very well!
:::

# Predictions {background-color="#2d2d2d"}

## Prediction Flow

![](diagrams/prediction-flow.svg){fig-align="center" width="95%"}

## Feature Importance: What Matters?

**Top 5 Most Important Features:**

```
1. policy_violation_score      28.5%
2. max_vulnerability_score     19.8%
3. privileged_container_ratio  15.2%
4. external_exposure            8.9%
5. process_baseline_violations  7.6%
```

::: {.fragment}
**Insight:** Policy violations and critical CVEs drive risk ranking more than other factors
:::

## Real Example: nginx-frontend

:::: {.columns}
::: {.column width="50%"}
**Deployment Characteristics:**

- Policy violations: 12 (severity 8.5)
- Vulnerabilities: 15 CVEs
- Privileged: Yes (ratio: 0.75)
- External exposure: Yes
- Image age: 180 days
:::

::: {.column width="50%"}
**Risk Prediction:**

- **Risk Score:** 7.4 / 10
- **Rank:** 15th of 1000

**Top Contributing Features:**

1. `policy_violation_score` â†’ +2.1
2. `max_vulnerability_score` â†’ +1.8
3. `privileged_container_ratio` â†’ +1.2
4. `external_exposure` â†’ +0.6
:::
::::

## Validation: Predicted vs Actual

**Validation Metrics (on production data):**

```json
{
  "mae": 0.34,           // Mean absolute error
  "rmse": 0.49,          // Root mean squared error
  "correlation": 0.87,   // Linear correlation
  "ndcg": 0.92,          // Ranking quality â­
  "within_30_percent": 87.5%
}
```

::: {.fragment}
**NDCG = 0.92** means model ranks 92% as well as perfect ranking!
:::

# Production & Future {background-color="#2d2d2d"}

## Current Status

::: incremental
âœ… **Implemented:**

- Full training pipeline with Central integration
- Feature extraction for deployments + images
- RandomForest model (1000 trees, NDCG-optimized)
- REST API endpoints for training and prediction
- Model storage and versioning
- Validation framework with NDCG tracking

ðŸ“¦ **Deployment:**

- Docker container with FastAPI service
- Model persistence to local/GCS storage
- gRPC and REST interfaces
:::

## API Endpoints

```bash
# Train model with Central data
POST /api/v1/training/central/train-full
  â†’ Returns: model_version, validation_ndcg

# Predict risk for deployment
POST /api/v1/predictions
  â†’ Returns: risk_score, feature_importance

# Validate model predictions
POST /api/v1/training/central/validate-predictions
  â†’ Returns: mae, rmse, correlation, ndcg

# List available models
GET /api/v1/models
  â†’ Returns: model metadata, versions
```

## Roadmap

::: incremental
**Short-term (Q1 2025):**

- Integration with ACS Console UI
- Model A/B testing framework
- Automated retraining pipeline

**Medium-term (Q2-Q3 2025):**

- Continuous learning from production feedback
- Model drift detection and alerting
- Multi-cluster model federation

**Long-term (Q4 2025+):**

- Temporal pattern detection (time-series)
- Anomaly detection for new threat patterns
- Active learning for high-uncertainty predictions
:::

## Key Takeaways

::: incremental
1. **RandomForest** is simple, robust, and explainable for risk ranking

2. **NDCG > 0.85** proves model ranks deployments effectively

3. **Feature importance** reveals which security issues matter most

4. **Synthetic scoring** enables bootstrap training without historical data

5. **Production-ready** with full API, storage, and validation
:::

## Questions?

::: {.r-stack}
![](diagrams/randomforest-architecture.svg){fig-align="center" width="60%"}
:::

**Resources:**

- Code: `stackrox/ml-risk-service`
- Docs: `learning.md` (comprehensive technical guide)
- API: `http://localhost:8090/docs` (OpenAPI)

---

**Thank you!**
