---
title: "Machine learning based ranking for risk"
subtitle: "Intelligent risk recommendations for ACS"
author: "Stephan He√üelmann"
date: "2025-11-05"
format:
  revealjs:
    chalkboard:
      buttons: false
    css: styles.css
    footer: "ACS Engineering | Frankfurt meetup 2025"
    preview-links: auto
    slide-number: true
    theme: simple
---

## Agenda

::: incremental
1. **The Challenge**: Why we need machine learning for risk ranking
2. **The Algorithm**: How a random forest works
3. **Training Pipeline**: From Central data to trained model
4. **Predictions**: How to rank deployments in production
5. **Vibe Coding**: Current prototype status
6. **Roadmap**: Possible improvements
:::

# The Challenge {background-color="#2d2d2d"}

## What Is Risk?

::: columns
::: {.column width="50%"}
::: incremental
- **ACS monitors thousands of deployments** across customer clusters
- Each deployment has **dozens of security characteristics**:
  - Policy violations
  - CVE vulnerabilities
  - Privileged containers
:::
:::

::: {.column width="50%"}
::: incremental
-
  - Network exposure
  - Process anomalies
  - ... and many more

- **Question:** Which deployments should security teams focus on first?
:::
:::
:::

## The Existing Risk Feature

![Current risk assessment in ACS](diagrams/current-risk.png){width="80%"}

## Shortcomings of Current Approach

::: incremental
- **üîí Intransparent**
  - The risk score is baked into ACS with a complex formula.
  - Customers cannot understand or validate how scores are calculated.

- **‚öôÔ∏è Inflexible**
  - Does not adapt to customer needs or emerging trends.
  - One-size-fits-all approach across all environments.
:::

## Current Approach: Rule-Based Multipliers

::: columns
::: {.column width="50%"}

**Feature multiplication**:

```
Risk Score =
  Policy Violations √ó
  Process Baseline √ó
  Vulnerabilities √ó
  Risky Components √ó
  Component Count √ó
  Image Age √ó
  ...
```
:::

::: {.column width="50%"}
**Drawbacks:**

::: incremental
- **Hardcoded formulas**
  - Manually tuned thresholds and weights

- **Cannot reverse the calculation**
  - Multiplied scores lose individual feature information
:::
:::
:::

## Example: Image Age Calculation

```go
// Creates a score that is:
// A) No risk when daysSinceCreated is < penalizeDaysFloor
if imageAgeInDays < penalizeDaysFloor {
    return
}

// B) Increases linearly between penalizeDaysFloor and penalizeDaysCeil
daysSincePenalized := imageAgeInDays - penalizeDaysFloor
scaledDays := float32(daysSincePenalized) / float32(penalizeDaysCeil-penalizeDaysFloor)
riskScore = float32(1) + float32(scaledDays*(maxMultiplier-1))

// C) Is 1.5 when duration is > penalizeDaysCeil
if riskScore > maxMultiplier {
    riskScore = maxMultiplier
}
```

## The Machine Learning Solution

::: incremental
- **Learn** from historical deployment data
- **Identify** which security features matter most
- **Rank** deployments by learned feature weight
- **Explain** what features contribute to high risk scores
- **Improve** continuously as new data arrives
:::

# The Algorithm {background-color="#2d2d2d"}

## Random Forest: The Committee Approach

**Analogy:** Assessing fire risk for a house

::: incremental
- Instead of **1 inspector** with a rigid checklist...
  - ... ask **1000 inspectors**
- Each inspector looks at different factors:
  - Electrical wiring + smoke detectors
  - Flammable materials + escape routes
  - Building age + maintenance history
- **Final assessment** = average of all 1000 opinions
:::

## Random Forest Architecture

![](diagrams/randomforest-architecture.svg){fig-align="center" width="90%"}

## Why Random Forest?

::: incremental
1. ‚úÖ **Robust against outliers**
   - If one tree makes a mistake, 999 others can correct it

2. ‚úÖ **Handles complexity**
   - Learns non-linear relationships automatically

3. ‚úÖ **Provides Explanations**
   - Feature importance: which security issues matter most

4. ‚úÖ **Simple Training**
   - No epochs, no backpropagation, no GPUs required
:::

## Why **not** Random Forest?

::: incremental
1. ‚ùå **Just a regression algorithm**
   - No actual AI. Not in the training data -> it won't be learned.

2. ‚ùå **Supervised learning**
   - Predictions are only as good the training input.

3. ‚ùå **Retraining**
   - Learning new things requires new training data + model retraining.
:::

## Example: One Decision Tree

```
Is vulnerability_score > 7.5?
‚îú‚îÄ YES ‚Üí Is privileged_container_ratio > 0.5?
‚îÇ         ‚îú‚îÄ YES ‚Üí Risk Score = 8.2
‚îÇ         ‚îî‚îÄ NO ‚Üí Is external_exposure = 1?
‚îÇ                  ‚îú‚îÄ YES ‚Üí Risk Score = 6.5
‚îÇ                  ‚îî‚îÄ NO ‚Üí Risk Score = 4.1
‚îî‚îÄ NO ‚Üí Is policy_violation_score > 3.0?
         ‚îú‚îÄ YES ‚Üí Risk Score = 5.0
         ‚îî‚îÄ NO ‚Üí Risk Score = 2.3
```

::: {.fragment}
**Final Prediction:** Average of 1000s such trees
:::

# Training Pipeline {background-color="#2d2d2d"}

## End-to-End Training Flow

![](diagrams/training-pipeline.svg){fig-align="center" width="100%"}

## Performance Metric: NDCG

**NDCG = Normalized Discounted Cumulative Gain**

::: incremental
- Measures **ranking quality** on 0-1 scale
- Values closer to **1.0** = better ranking

**Example:**
```
True ranking:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
Model ranking: [1, 2, 3, 4, 5, 6, 7, 9, 8, 10]
                                     ‚Üë Small error at top
NDCG ‚âà 0.98  (98% as good as perfect ranking)
```
:::

## Typical Performance

:::: {.columns}
::: {.column width="50%"}
**Training Metrics**

- NDCG: **0.75-0.95**
- Training time: **~60 sec**
:::

::: {.column width="50%"}
**Model Characteristics**

- Feature count: **~20**
- Training samples: **100-1000**
- Model size: **~20 MB**
- Trees: **1000**
:::
::::

::: {.fragment}
**Validation NDCG > 0.85** means model ranks deployments very well!
:::

# Predictions {background-color="#2d2d2d"}

## Prediction Flow

![](diagrams/prediction-flow.svg){fig-align="center" width="95%"}

## Feature Importance: What Matters?

**Example: Top 5 most important features**

```
1. policy_violation_score      28.5%
2. max_vulnerability_score     19.8%
3. privileged_container_ratio  15.2%
4. external_exposure            8.9%
5. process_baseline_violations  7.6%
```

:::::: {.fragment}
::: incremental
- **Insight:** Policy violations and critical CVEs drive risk ranking more than other factors.
- **Detail:** Calculated for training data and each prediction.
:::
::::::

# Vibe Coding {background-color="#2d2d2d"}

## Current Status

::: incremental
ü§ñ **Model:**

- Full training pipeline with Central integration
- Feature extraction for deployments + images
- RandomForest model (1000 trees, NDCG-optimized)
- REST API endpoints for training and prediction
- Model storage and versioning
- Validation framework with NDCG tracking

üì¶ **Deployment:**

- Docker container with FastAPI service
- Model persistence to local/GCS storage
- gRPC and REST interfaces
:::

## API Endpoints

```bash
# Train model with Central data
POST /api/v1/training/central/train-full
  ‚Üí Returns: model_version, validation_ndcg

# Predict risk for deployment
POST /api/v1/predictions
  ‚Üí Returns: risk_score, feature_importance

# Validate model predictions
POST /api/v1/training/central/validate-predictions
  ‚Üí Returns: mae, rmse, correlation, ndcg

# List available models
GET /api/v1/models
  ‚Üí Returns: model metadata, versions
```

## Key Takeaways

::: incremental
1. **RandomForest** is simple, robust, and explainable for risk ranking

2. **NDCG > 0.85** proves model ranks deployments effectively

3. **Feature importance** reveals which security issues matter most

4. **Synthetic scoring** enables bootstrap training without historical data

5. **Production-ready** with full API, storage, and validation
:::

## Questions?

::: {.r-stack}
![](diagrams/randomforest-architecture.svg){fig-align="center" width="100%"}
:::

**Resources:**

- Code: `stackrox/ml-risk-service`
- Docs: `learning.md` (comprehensive technical guide)
